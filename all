---
title: "Assignment 3"
author: "Mikolaj Molski"
date: "2023-12-04"
output: pdf_document
---

```{r setup, echo=TRUE}
library(knitr)
library(palmerpenguins)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 80))
```

# Exercise 1

## 1

```{r}
data(penguins)
df <- as.data.frame(penguins)
```

Penguins is a subset of `penguins_raw`. Object is of a type tibble

## 2

```{r}
df_2 <- df[,c(1,2)]
table(df_2)
```

There are 3 penguin species present in the data frame. There is only one specie (Adelie), which is present on more than one island

## 3

```{r}
blm_C <- df$bill_length_mm[which(df$species == "Chinstrap")]
blm_G <- df$bill_length_mm[which(df$species == "Gentoo")]
test <- t.test(x = blm_C, y = blm_G, alternative = "less", var.equal = F)
test$p.value
```

Setting $\alpha = 0.05$, I do not reject the null hypothesis of $\mu_C \geq \mu_G$

# Exercise 2

## 1

```{r}
sum(is.na(df$species))
sum(is.na(df$body_mass_g))
```

Yes, there are 2 penguins for which body_mass is missing.

```{r}
df_3 <- df[-which(is.na(df$body_mass_g)),]
```

## 2

```{r}
plot(df_3$body_mass_g ~ df_3$species, xlab = "Species",
     ylab = "Body mass in grams",
     main = "Comparison of body weight across different species of penguins",
     col = c("steelblue2","magenta","cyan"))
```

I can clearly observe that Gentoo species tend to have bigger weight comparing to Adelie and Chinstrap, which show simmilar distribution of body mass.

```{r}
bm_A <- df_3$body_mass_g[which(df_3$species == "Adelie")]
bm_C <- df_3$body_mass_g[which(df_3$species == "Chinstrap")]
bm_G <- df_3$body_mass_g[which(df_3$species == "Gentoo")]
```

```{r}
par(bty = 'l')
plot(density(bm_A), col = "steelblue2", xlim = c(2000,7000),ylim = c(0,1.102e-03),
     ylab = "Density",
     xlab = "Body mass in grams",
     main = "Comparison of body weight across different species of penguins")
lines(density(bm_C), col = "magenta4")
lines(density(bm_G), col = "cyan3")
```

I made 2 plots because I wasn't sure which one I should make.

## 3

```{r}
df_3$body_mass_kg <- df_3$body_mass_g / 1000
```

```{r}
m_bm_kg_A <- mean(df_3$body_mass_kg[which(df_3$species == "Adelie")])
m_bm_kg_C <- mean(df_3$body_mass_kg[which(df_3$species == "Chinstrap")])
m_bm_kg_G <- mean(df_3$body_mass_kg[which(df_3$species == "Gentoo")])
sd_bm_kg_A <- sd(df_3$body_mass_kg[which(df_3$species == "Adelie")])
sd_bm_kg_C <- sd(df_3$body_mass_kg[which(df_3$species == "Chinstrap")])
sd_bm_kg_G <- sd(df_3$body_mass_kg[which(df_3$species == "Gentoo")])
```

Function evaluating negative log-likelihood:

```{r}
neg.logl = function(theta, pi1, pi2, pi3, w1, w2, w3, x) {
  mu1 = theta[1]
  mu2 = theta[2]
  mu3 = theta[3]
  
  sigma1 = exp(theta[4]) # transformation !
  sigma2 = exp(theta[5]) # transformation !
  sigma3 = exp(theta[6]) # transformation !
  
  f.x1 = pi1 * dnorm(x, mu1, sigma1)
  f.x2 = pi2 * dnorm(x, mu2, sigma2)
  f.x3 = pi3 * dnorm(x, mu3, sigma3)
  
  # negative log-likelihood
  - sum(w1 * log(f.x1) + w2 * log(f.x2) + w3 * log(f.x3))
}
```

## 4

I have chosen my starting points so that expected value of first iteration probability memberships for jth component is equal to jth pi. I put $\mu$ values to be equal to the means of body mass values for 3 species. I set $\sigma$ values to correspond to standard deviations of body mass values.

```{r}
EM_function <- function(x, pi_start,n.iter = 500){

  n = length(x)
  
  pi1hat = rep(NA, n.iter)
  pi2hat = rep(NA, n.iter)
  pi3hat = rep(NA, n.iter)
  
  p1hat = matrix(NA, n.iter, n)
  p2hat = matrix(NA, n.iter, n)
  p3hat = matrix(NA, n.iter, n)
  
  theta_hat = matrix(NA, n.iter, 6)
  
  pi1hat[1] = pi_start[1]
  pi2hat[1] = pi_start[2]
  pi3hat[1] = 1 - pi1hat[1] - pi2hat[1]

  p1hat[1, ] <- runif(n, pi1hat[1] - 0.8*pi_start[1], pi1hat[1] + 0.8*pi_start[1])
  p2hat[1, ] <- runif(n, pi2hat[1] - 0.8*pi_start[2], pi2hat[1] + 0.8*pi_start[2])
  p3hat[1, ] <- runif(n, pi2hat[1] - 0.8*pi3hat[1], pi2hat[1] + 0.8*pi3hat[1]) 

  theta_hat[1, ] = optim(c(m_bm_kg_A,m_bm_kg_C,m_bm_kg_G,sd_bm_kg_A,sd_bm_kg_C,sd_bm_kg_G),
                         function(theta) neg.logl(theta, pi1hat[1], pi2hat[1], pi3hat[1],
                                                  p1hat[1, ], p2hat[1, ], p3hat[1, ], x))$par

  for (t in 2:n.iter) { 
    #E step: update individual probability memberships 
  
    p.temp= cbind( 
      p1hat[t-1,]*dnorm(x,theta_hat[t-1, 1],exp(theta_hat[t-1, 4])),
      p2hat[t-1,]*dnorm(x,theta_hat[t-1, 2],exp(theta_hat[t-1, 5])),
      p3hat[t-1,]*dnorm(x,theta_hat[t-1, 3],exp(theta_hat[t-1, 6])))
    p1hat[t,]=p.temp[,1]/rowSums(p.temp) 
    p2hat[t,]=p.temp[,2]/rowSums(p.temp)
    p3hat[t,]=p.temp[,3]/rowSums(p.temp)
  
    #M step: update parameter estimates 
  
    pi1hat[t] = mean(p1hat[t,])
    pi2hat[t] = mean(p2hat[t,])
    pi3hat[t] = mean(p3hat[t,])
  
    # print(c(t, theta_hat[t-1,],pi1hat[t],pi2hat[t],pi3hat[t],p1hat[t,], p2hat[t,], p3hat[t,]))
    
    theta_hat[t,]= optim(theta_hat[t-1,], function(theta) {
      neg.logl(theta, pi1hat[t], pi2hat[t], pi3hat[t], p1hat[t,], p2hat[t,], p3hat[t,], x)})$par
    
   }
  
  logl.last = -neg.logl(theta_hat[n.iter, ], pi1hat[n.iter], pi2hat[n.iter], pi3hat[n.iter],
                           p1hat[n.iter, ], p2hat[n.iter, ], p3hat[n.iter, ], x)
  
  out = list('logl' = logl.last,
             'theta_hat' = c(theta_hat[n.iter,1],
                             theta_hat[n.iter,2],
                             theta_hat[n.iter,3],
                             exp(theta_hat[n.iter,4]),
                             exp(theta_hat[n.iter,5]),
                             exp(theta_hat[n.iter,6])),
             'pi' = c(pi1hat[n.iter],
                      pi2hat[n.iter],
                      pi3hat[n.iter]),
             'p1_last' = p1hat[n.iter, ],
             'p2_last' = p2hat[n.iter, ],
             'p3_last' = p3hat[n.iter, ],
             'pi_vals_for_conv_check' = cbind(pi1hat,
                      pi2hat,
                      pi3hat))
  
  return(out)
}
```

```{r}
set.seed(4025814)
x <- df_3$body_mass_kg
run_1 <- EM_function(x, c(0.2,0.3), n.iter = 500)
run_2 <- EM_function(x, c(0.4,0.5), n.iter = 500)
run_3 <- EM_function(x, c(0.1,0.4), n.iter = 500)
```

## 5


```{r}
logl.vals = c(run_1$logl,run_2$logl,run_3$logl)
logl.vals
```

I am going to pick the solution with the biggest log-likelihood. 
That solution is going to be the most "likely" to be true.

```{r}
EM_estimates = run_2
c("logl" = EM_estimates$logl, "theta_hat" = EM_estimates$theta_hat, "pi" = EM_estimates$pi)
```

## 6

```{r}
n.iter <- 500
plot(1:n.iter, run_2$pi_vals_for_conv_check[,1], pch = 22, ylim = c(0.1, 0.4),cex = .6,
     xlab = "iteration number", ylab = "pi1 value", main = "Convergence check")
plot(1:n.iter, run_2$pi_vals_for_conv_check[,2], pch = 22, ylim = c(0.1, 0.5),cex = .6,
     xlab = "iteration number", ylab = "pi2 value", main = "Convergence check")
plot(1:n.iter, run_2$pi_vals_for_conv_check[,3], pch = 22, ylim = c(0.1, 0.4),cex = .6,
     xlab = "iteration number", ylab = "pi3 value", main = "Convergence check")
```

According to plots, all of my probability values converged.

## 7
My maximum likelihood estimates are:

```{r}
c("pi1" = run_2$pi[1], "pi2" = run_2$pi[2], "pi3" = run_2$pi[3],
  "mu1" = run_2$theta_hat[1], "mu2" = run_2$theta_hat[2], "mu3" = run_2$theta_hat[3],
  "sigma1" = run_2$theta_hat[4], "sigma2" = run_2$theta_hat[5], "sigma3" = run_2$theta_hat[6])
```

The weights of 3 components are relatively similar. The $\mu$ values are relatively close. Maybe $\mu_1$ is slightly too large.

## 8

```{r}
W1 <- run_2$p1_last
W2 <- run_2$p2_last
W3 <- round(run_2$p3_last,3)
```

```{r}
hist(x, 20, prob = T, col = 'steelblue2', ylim = c(0, 1))
hist(rnorm(10000, run_2$theta_hat[1], run_2$theta_hat[4]),
     col = 'red', lwd = 2, xlab = "W1 distribution", main = "")
hist(rnorm(10000, run_2$theta_hat[2], run_2$theta_hat[5]),
     col = 'green2', lwd = 2, xlab = "W2 distribution", main = "")
hist(rnorm(10000, run_2$theta_hat[3], run_2$theta_hat[6]),
     col = 'pink', lwd = 2, xlab = "W3 distribution", main = "")
```

## 9

```{r}
predictedComponent <- rep(NA, 342)

for (i in 1:342) {
  if(W1[i] == 1){
    predictedComponent[i] = 1
  } else if(W2[i] == 1){
    predictedComponent[i] = 2
  } else{
    predictedComponent[i] = 3
  }
}
```

## 10

```{r}
table(predictedComponent, df_3$sex)
table(predictedComponent, df_3$species)
```

## 11

For `predictedComponent = 1`, I would guess male, according to my frequency distribution.
For `predictedComponent = 2`, female is my guess.
For `predictedComponent = 3`, male is my guess.

## 12

For species we have a guess `Gentoo` for `predictedComponent = 1`, `Adelie` for `predictedComponent = 2` and `Adelie` for `predictedComponent = 3`
